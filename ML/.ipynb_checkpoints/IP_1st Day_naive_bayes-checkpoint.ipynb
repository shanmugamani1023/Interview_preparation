{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afd751b7",
   "metadata": {},
   "source": [
    "# Today i am going to learn about Naive Bayes Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76de9031",
   "metadata": {},
   "source": [
    "references: https://youtu.be/mlumJPFvooQ?si=ibvZ3TOr-wMWsTrX -IP1 introduction\n",
    "\n",
    "https://www.youtube.com/watch?v=jS1CKhALUBQ -Naive bayes intro\n",
    "\n",
    "https://www.youtube.com/watch?v=jS1CKhALUBQ -Real time example on text dataset\n",
    "\n",
    "https://www.youtube.com/watch?v=O2L2Uv9pdDA -Real time example video\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377af31b",
   "metadata": {},
   "source": [
    "# 1.What is naive bayes theorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19fcc2a",
   "metadata": {},
   "source": [
    "### P(A/B)=(p(B/A)*p(A)) / p(B)\n",
    "\n",
    "### B-independent features(x1,x2,x3,....xn)\n",
    "\n",
    "### A-dependent features(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abb918d",
   "metadata": {},
   "source": [
    "# 2.Mathmetical intution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110d235d",
   "metadata": {},
   "source": [
    "### Y - take different type of values.ex-true or false.\n",
    "###  we will find the probability of true and false with respect to given set of independent features.\n",
    "###  we will choose the result value based on the higher probabilty value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a668bc25",
   "metadata": {},
   "source": [
    "# 3.Real time example  (binary classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68641f90",
   "metadata": {},
   "source": [
    "### refer :4.https://www.geeksforgeeks.org/naive-bayes-classifiers/"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a99a0201",
   "metadata": {},
   "source": [
    "# Outlook\t  Temperature\tPlay Golf  yes_for_sunny   No_for_sunny   yes_for_rainy    no_for_rainy  yes_frcast  no_cast\n",
    "0\tRainy\t  Hot\t\t\tNo           3                  2              2               3            4\n",
    "1\tRainy\t  Hot\t\t\tNo  \n",
    "2\tOvercast  Hot\t\t\tYes\n",
    "3\tSunny\t  Mild\t\t    Yes\n",
    "4\tSunny\t  Cool\t\t    Yes\n",
    "5\tSunny\t  Cool\t\t    No\n",
    "6\tOvercast  Cool\t\t    Yes\n",
    "7\tRainy\t  Mild\t        No\n",
    "8\tRainy\t  Cool\t\t    Yes\n",
    "9\tSunny\t  Mild\t\t    Yes\n",
    "10\tRainy\t  Mild\t        Yes\n",
    "11\tOvercast  Mild\t        Yes\n",
    "12\tOvercast  Hot\t        Yes\n",
    "13\tSunny\t  Mild\t\t    No"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aa6b2b67",
   "metadata": {},
   "source": [
    "steps:\n",
    "1.frequency table (we need to find how many output class is available for each independent class ) \n",
    "2.Conditional probabilty table \n",
    "3.we l find probabilty of each class with respect to given class"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a006fe97",
   "metadata": {},
   "source": [
    "outlook   yes   NO     p(y)              p(n)   \n",
    "\n",
    "Rainy     3      2    3/9                 3/5\n",
    "\n",
    "Overcast  4      0     4/9                 0/5\n",
    "\n",
    "sunny     2     3     2/9 =sunny/yes)     3/5=p(sunny/no)\n",
    "\n",
    "total=3  ,ty=9 ,tn=5"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e82a072d",
   "metadata": {},
   "source": [
    "Temperature    yes      no      p(y)                 p(n)\n",
    "\n",
    "HOt             2       2       2/9(p(hot/yes)        2/5 =p(hot/no)       \n",
    " \n",
    "mild            4        2       4/9                   2/5\n",
    "  \n",
    "cool            3        1       3/9                    1/9   \n",
    "             \n",
    "             ty=9,      tn=5"
   ]
  },
  {
   "cell_type": "raw",
   "id": "338d6d0a",
   "metadata": {},
   "source": [
    "play            prob \n",
    "\n",
    "yes    avg    9/14=(p(yes))\n",
    "\n",
    "\n",
    "NO     avg=5      5/14\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcb85a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so,we can find the probabilty table ,"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6738b01c",
   "metadata": {},
   "source": [
    "<!-- ex:if we given a  new input today(sunny,hot) -->\n",
    "<!-- then  -->\n",
    "<!-- how the calculation will work  -->\n",
    "\n",
    "we need to take both dependent category ,\n",
    "here yes and no,\n",
    "so, we need to find how much probabilty of yes based on the given indepndent features and probabilty of no based on independent features.\n",
    "\n",
    " p(yes/today) =p(sunny/yes)*p(hot/yes) *p(yes) / p(today)\n",
    " \n",
    " today=independent features\n",
    " Since, P(today) is common in both probabilities, we can ignore P(today) and find proportional probabilities as:\n",
    " \n",
    " so,here \n",
    " \n",
    " p(yes/today)=(2/9*2/9*9/14)=0.03174\n",
    " \n",
    " and \n",
    " \n",
    " p(no/today) =p(sunny/no)*p(hot/no)*p(no)\n",
    "             =3/5*2/5*5/14\n",
    "             =0.0857\n",
    "\n",
    "we need to normalize this values we can take any one ,\n",
    "\n",
    "p(yes/today)=0.031 /(0.031+0.0857)=0.2656383890317052\n",
    "\n",
    "p(no/today)=0.0857 /(0.031+0.0857)=0.7343616109682948\n",
    "\n",
    "so ,prob 0.73 for no\n",
    "    prob 0.26 for yes\n",
    "    \n",
    "    so ,0.73 > 0.26 ,hence we choose no as a result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d9d3fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2656383890317052"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_yes=(2/9*2/9*9/14)\n",
    "\n",
    "# normalization\n",
    "p_yes=0.031 /(0.031+0.0857)\n",
    "p_yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78312cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7343616109682948"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_no=3/5*2/5*5/14\n",
    "p_no=0.0857 /(0.031+0.0857)\n",
    "p_no"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5c5a2b",
   "metadata": {},
   "source": [
    "# Refer this link for multiclass classification-https://youtu.be/YeD-Ntq96Lo?si=Kw-YVkY3utWLD9tZ (Multiclass classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7e49f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1602173",
   "metadata": {},
   "source": [
    "# 4.Real time implementation(code implementation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dd778d",
   "metadata": {},
   "source": [
    "# Refer this link -https://www.youtube.com/watch?v=nHIUYwN-5rM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93fbc14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spam mail detector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a81cff-da9c-4b06-806a-1780041dee12",
   "metadata": {},
   "source": [
    "# TYpes of bayes classfier\n",
    "# 1.Gaussian naive bayes\n",
    "# 2.Bernoulis naive bayes\n",
    "# 3.Multinomial naive bayes\n",
    "# 4.complement naive bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cac44ec-175f-4c1b-aeae-70dcc8a3958a",
   "metadata": {},
   "source": [
    "Yes, in Naive Bayes classification, there are generally four common methods:\n",
    "\n",
    "1. **Gaussian Naive Bayes:**\n",
    "   - Assumes that the features follow a normal distribution. It is suitable for continuous data.\n",
    "\n",
    "2. **Multinomial Naive Bayes:**\n",
    "   - Appropriate for discrete data, such as text data represented as word frequency counts. It is commonly used in natural language processing (NLP) tasks.\n",
    "\n",
    "3. **Bernoulli Naive Bayes:**\n",
    "   - Designed for binary or Boolean features. It's often used in text classification tasks where the presence or absence of a particular feature is relevant.\n",
    "\n",
    "4. **Complement Naive Bayes:**\n",
    "   - A variation of Multinomial Naive Bayes that is particularly useful for imbalanced datasets. It adjusts for imbalances by using the complement of each class's probability.\n",
    "\n",
    "Each method has its own assumptions about the distribution of the data and is suitable for different types of features. The choice of which method to use depends on the nature of your data and the problem you are trying to solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2673d63c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5870a901",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53afd0df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ex.Gaussian naive bayes\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5d4e37e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 4)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "X,y=load_iris(return_X_y=True)\n",
    "\n",
    "#split data\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,y,test_size=0.3,random_state=1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a746cc00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call the model\n",
    "model=GaussianNB()\n",
    "model\n",
    "#fit model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd5ac077-63a5-455b-b030-845a19ff48f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2032ccc3-1521-4681-aa1f-61b326440855",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ec6d56e3-50aa-4ada-8683-df63dfba2e58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 45 points : 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0], (Y_test != result).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dd3959-a846-4394-828d-0806d6ca643f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a1fd4b1-2c16-45eb-b45a-122abc8312b7",
   "metadata": {},
   "source": [
    "# Evaluating A Classification Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b99e91b-e006-4dbe-941c-d56f2f75f8a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a46bc50-6139-4159-a221-8e3d9a2ef5ba",
   "metadata": {},
   "source": [
    "# confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "04e69b07-532e-4ccd-9807-2a0caff3a17a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14,  0,  0],\n",
       "       [ 0, 16,  2],\n",
       "       [ 0,  1, 12]], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Y_test,y_pred)\n",
    "\n",
    "# here x direction predicted class\n",
    "# y direction actual class\n",
    "# ref this link -https://www.analyticsvidhya.com/blog/2021/12/evaluation-of-classification-model/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c2d655-831e-448c-80d3-5502a12f13fd",
   "metadata": {},
   "source": [
    "# Precision\n",
    "Precision is defined as the ratio of True Positives count to total True Positive count made by the model.\n",
    "Precision =  TP/(TP+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a4ef94d-ff91-4fed-a686-6338b22e34c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.94117647, 0.85714286])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision_score(Y_test,y_pred,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d269bfcb-64fd-48e9-a1a2-dc6197a5a435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f250ae9-aa76-4b1f-a50c-a8d5da95b911",
   "metadata": {},
   "source": [
    "# Recall\n",
    "Recall is defined as the ratio of True Positives count to the total Actual Positive count.\n",
    "Recall = TP/(TP+FN)\n",
    "Recall is also called “True Positive Rate” or “sensitivity”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "98b758e1-7726-4edb-897a-47764320ce7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.88888889, 0.92307692])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recall_score(Y_test, y_pred,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df3ca83-c9bc-41b1-b9b2-223a2e4e91e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06d738cb-2730-496c-a7f3-b4984b77112e",
   "metadata": {},
   "source": [
    " # It is called the F1 score. It is the harmonic mean of recall & precision. The harmonic mean is more sensitive to low values, so the F1 will be high only when both precision & recall are high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "319a606b-1ade-4d98-b935-73778ed3904d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.91428571, 0.88888889])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(Y_test, y_pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd6fc0d-e167-4d01-83b9-a5c74fa0ca32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6c8c68c",
   "metadata": {},
   "source": [
    "# 5.Advantages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d095505e-9792-4498-8e6d-fe65a1c2f1c2",
   "metadata": {},
   "source": [
    "# 1.it can handle large no of datasets\n",
    "# 2.it can handel large no of features\n",
    "# 3.it converges faster\n",
    "(all points works because of computations based on probabilty)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa3c80e",
   "metadata": {},
   "source": [
    "# 6.Disadvantages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7310a5-1fce-4ac7-bc28-1e0474935c27",
   "metadata": {},
   "source": [
    "# Co-related features may decrease the performance of the model ,because it may affects probality computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96578d50-ce3b-4f5e-b092-a343ffb4b746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f41aed3a",
   "metadata": {},
   "source": [
    "# 7.Feature scaling required or not ?why ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211dee81-da89-4eff-9e69-a317d990ff55",
   "metadata": {
    "tags": []
   },
   "source": [
    "# NO need to do feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0a6653-6590-45c7-a76a-97ee3bebe134",
   "metadata": {},
   "source": [
    "Naive Bayes algorithms, including Multinomial Naive Bayes and Bernoulli Naive Bayes, are not typically sensitive to feature scaling. These algorithms work with the probabilities of different features occurring given a particular class and make the assumption that features are conditionally independent. Because of this assumption, the relative scales of the features don't affect the model's performance.\n",
    "\n",
    "Therefore, in most cases, feature scaling is not required for Naive Bayes algorithms. You can usually apply these algorithms directly to your dataset without normalizing or standardizing the features.\n",
    "\n",
    "However, it's essential to note that if you have other algorithms or methods in your overall workflow that are sensitive to feature scales (such as distance-based methods like k-nearest neighbors or support vector machines), you might still want to scale your features for consistency across your entire process. But for Naive Bayes specifically, it's not a critical preprocessing step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904f1f2e",
   "metadata": {},
   "source": [
    "# 8.Impact of missing values and how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d8e3aa",
   "metadata": {},
   "source": [
    "# Naive bayes robust to missing values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9c7e16-848b-4408-a826-a83c4cc37060",
   "metadata": {},
   "source": [
    "Naive Bayes algorithms, particularly the Multinomial Naive Bayes and Bernoulli Naive Bayes variants commonly used in text classification and other discrete data applications, can handle missing values without requiring imputation.\n",
    "\n",
    "The reason for this resilience to missing values lies in the nature of the independence assumption that Naive Bayes makes. The \"naive\" part of Naive Bayes implies that the algorithm assumes all features are independent given the class label. Therefore, the absence of information (missing values) for one feature does not influence the estimation of the probabilities for other features.\n",
    "\n",
    "Here are a few points to consider:\n",
    "\n",
    "1. **Ignoring Missing Values:**\n",
    "   - Naive Bayes can simply ignore the missing values during the training process and still provide reasonable results.\n",
    "\n",
    "2. **Imputation not Required:**\n",
    "   - Unlike some other machine learning algorithms that might require imputation of missing values before training, Naive Bayes does not necessitate this preprocessing step.\n",
    "\n",
    "3. **Robustness to Sparse Data:**\n",
    "   - Naive Bayes is also known to be robust to sparse data, which means it can handle datasets with a large number of missing values or zero entries.\n",
    "\n",
    "While Naive Bayes is robust to missing values, it's always a good practice to carefully analyze the reasons behind missing data in your dataset and consider whether imputation or other strategies might be beneficial for other aspects of your analysis or for the interpretability of your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0127f3a-dddb-4b86-b1e5-6fdaeed1b276",
   "metadata": {},
   "source": [
    "# 9.Naive bayes robust to outlliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce7ce9a-dd35-4218-b2a6-dccb66d3655d",
   "metadata": {},
   "source": [
    "Naive Bayes algorithms, including Multinomial Naive Bayes and Bernoulli Naive Bayes, are generally considered to be robust to outliers. The reason for this lies in the nature of the probabilistic model and the assumption of independence among features.\n",
    "\n",
    "Here are a few reasons why Naive Bayes tends to be robust to outliers:\n",
    "\n",
    "1. **Independence Assumption:**\n",
    "   - Naive Bayes assumes that features are conditionally independent given the class. This means that the impact of outliers in one feature is limited to that specific feature, and it does not significantly affect the probabilities of other features.\n",
    "\n",
    "2. **Robustness to Irrelevant Features:**\n",
    "   - Naive Bayes is also known to be robust to irrelevant features. Outliers in irrelevant features are less likely to have a significant impact on the classification process.\n",
    "\n",
    "3. **Probabilistic Nature:**\n",
    "   - Naive Bayes calculates probabilities based on occurrences of features within each class. Outliers may affect the probability estimates for individual features, but since these probabilities are combined in a multiplicative manner, the overall impact of outliers tends to be mitigated.\n",
    "\n",
    "While Naive Bayes is generally robust to outliers, it's crucial to note that the performance of any machine learning algorithm can be influenced by the severity and distribution of outliers in the dataset. Additionally, if outliers are indicative of errors or anomalies in the data, it's important to address and understand them in the context of your specific application. Preprocessing steps such as outlier detection and handling might still be relevant depending on the nature of your data and the goals of your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547c2b35-9e31-4681-b72f-e9867ae89c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe17372-27e7-4855-9817-689438d6c8a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc392ddb-22db-4afb-9756-904e570ae4c9",
   "metadata": {},
   "source": [
    "# 10.What Are the Basic Assumption?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5501e5e0-45a9-4926-8952-11f757e0fbf1",
   "metadata": {},
   "source": [
    "# Features Are Independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b0c020-8237-4f41-b4c2-655b95160e66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb9027c7-1b40-4d7d-9b73-5e307db9dbe0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 11.Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38af8cea-f916-49ae-8112-407c7c807855",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "# Spam classification\n",
    "# twitter sentiment analysis\n",
    "# document categorization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
